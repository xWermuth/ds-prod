{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sparselsh import LSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based, regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load food.com data\n",
    "directory = 'data/food.com'\n",
    "df_recipe_rating = pd.read_csv(f'{directory}/recipe_ratings.csv')\n",
    "df_recipe = pd.read_csv(f'{directory}/recipe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>calories</th>\n",
       "      <th>fat</th>\n",
       "      <th>sugar</th>\n",
       "      <th>sodium</th>\n",
       "      <th>protein</th>\n",
       "      <th>saturated</th>\n",
       "      <th>carbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137739</td>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>51.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31490</td>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>173.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112140</td>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>130</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>269.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59389</td>\n",
       "      <td>alouette  potatoes</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>368.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44061</td>\n",
       "      <td>amish  tomato ketchup  for canning</td>\n",
       "      <td>190</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>352.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id                                        name  minutes  n_steps  \\\n",
       "0     137739  arriba   baked winter squash mexican style       55       11   \n",
       "1      31490            a bit different  breakfast pizza       30        9   \n",
       "2     112140                   all in the kitchen  chili      130        6   \n",
       "3      59389                          alouette  potatoes       45       11   \n",
       "4      44061          amish  tomato ketchup  for canning      190        5   \n",
       "\n",
       "   n_ingredients  calories   fat  sugar  sodium  protein  saturated  carbs  \n",
       "0              7      51.5   0.0   13.0     0.0      2.0        0.0    4.0  \n",
       "1              6     173.4  18.0    0.0    17.0     22.0       35.0    1.0  \n",
       "2             13     269.8  22.0   32.0    48.0     39.0       27.0    5.0  \n",
       "3             11     368.1  17.0   10.0     2.0     14.0        8.0   20.0  \n",
       "4              8     352.9   1.0  337.0    23.0      3.0        0.0   28.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2046</td>\n",
       "      <td>4684</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2046</td>\n",
       "      <td>517</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1773</td>\n",
       "      <td>7435</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1773</td>\n",
       "      <td>278</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2046</td>\n",
       "      <td>3431</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698896</th>\n",
       "      <td>926904</td>\n",
       "      <td>457971</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698897</th>\n",
       "      <td>2002312797</td>\n",
       "      <td>27208</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698898</th>\n",
       "      <td>1290903</td>\n",
       "      <td>131607</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698899</th>\n",
       "      <td>226867</td>\n",
       "      <td>363072</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698900</th>\n",
       "      <td>2000498330</td>\n",
       "      <td>314535</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698901 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  recipe_id  rating\n",
       "0             2046       4684     5.0\n",
       "1             2046        517     5.0\n",
       "2             1773       7435     5.0\n",
       "3             1773        278     4.0\n",
       "4             2046       3431     5.0\n",
       "...            ...        ...     ...\n",
       "698896      926904     457971     5.0\n",
       "698897  2002312797      27208     5.0\n",
       "698898     1290903     131607     5.0\n",
       "698899      226867     363072     5.0\n",
       "698900  2000498330     314535     5.0\n",
       "\n",
       "[698901 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipe_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  2.4448826476980808e-30\n"
     ]
    }
   ],
   "source": [
    "#EXERCISE: Build a content-based recommender system that uses linear regression \n",
    "#          to predict ratings.\n",
    "#          Try it out on users with a high number of ratings.\n",
    "#          Try some train-test split to evaluate performance.\n",
    "\n",
    "#select the ratings of a specific user \n",
    "\n",
    "\n",
    "sorted_users = df_recipe_rating.groupby([\"user_id\"]).agg(count=(\"user_id\", \"count\")).sort_values(\"count\", ascending=False)\n",
    "target_id = sorted_users.index[0]\n",
    "df_user = df_recipe_rating[df_recipe_rating['user_id']==target_id][['recipe_id','rating']]\n",
    "df_rec = pd.merge(df_user, df_recipe, on='recipe_id', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "# define features\n",
    "features = [\"minutes\", \n",
    "            \"n_steps\", \n",
    "            \"n_ingredients\", \n",
    "            \"calories\", \n",
    "            \"fat\", \n",
    "            \"sugar\",\n",
    "            \"sodium\",\n",
    "            \"protein\",\n",
    "            \"saturated\",\n",
    "            \"carbs\"\n",
    "        ] \n",
    "\n",
    "# split training and test\n",
    "x = df_rec.drop([\"recipe_id\" , \"name\"], axis=1)\n",
    "y = df_rec[\"rating\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True)\n",
    "\n",
    "\n",
    "model = LinearRegression();\n",
    "\n",
    "predicted = model.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "\n",
    "expected = []\n",
    "for index, row in x_test.iterrows():\n",
    "    expected.append(row['rating'])\n",
    "\n",
    "mse = (np.square(expected - predicted)).mean()\n",
    "\n",
    "print(f\"mse:  {mse}\")\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based, KNN (with LSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/movielens/ml-latest-small'\n",
    "#directory = 'data/movielens/ml-latest' #change into this one for the full dataset (slow)\n",
    "\n",
    "df_movies = pd.read_csv(f'{directory}/movies.csv')\n",
    "df_ratings = pd.read_csv(f'{directory}/ratings.csv')\n",
    "df_tags = pd.read_csv(f'{directory}/tags.csv')\n",
    "\n",
    "#transform tags such that they are lower-case, single-word tokens\n",
    "df_tags['tag'] = df_tags['tag'].apply(lambda x: str(x).lower().replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>highly_quotable</td>\n",
       "      <td>1445714996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>will_ferrell</td>\n",
       "      <td>1445714992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>boxing_story</td>\n",
       "      <td>1445715207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>mma</td>\n",
       "      <td>1445715200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag   timestamp\n",
       "0       2    60756            funny  1445714994\n",
       "1       2    60756  highly_quotable  1445714996\n",
       "2       2    60756     will_ferrell  1445714992\n",
       "3       2    89774     boxing_story  1445715207\n",
       "4       2    89774              mma  1445715200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: Calculate item profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"artsy\"</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06_oscar_nominated_best_movie_-_animation</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900s</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920s</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950s</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>younger_men</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zither</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoe_kazan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zombies</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooey_deschanel</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1475 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           count\n",
       "tag                                             \n",
       "\"artsy\"                                        1\n",
       "06_oscar_nominated_best_movie_-_animation      3\n",
       "1900s                                          1\n",
       "1920s                                          2\n",
       "1950s                                          2\n",
       "...                                          ...\n",
       "younger_men                                    1\n",
       "zither                                         1\n",
       "zoe_kazan                                      1\n",
       "zombies                                        6\n",
       "zooey_deschanel                                1\n",
       "\n",
       "[1475 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculates the lexicon of most frequent tags.\n",
    "tag_frequency_threshold = 5 # increase number to filter\n",
    "# sorted_users = df_recipe_rating.groupby([\"user_id\"]).agg(count=(\"user_id\", \"count\")).sort_values(\"count\", ascending=False)\n",
    "df_lexicon = df_tags.groupby(\"tag\").agg(count=(\"tag\", \"count\")) # get a dataframe with tags and respective counts\n",
    "# discard movies with no tags\n",
    "item_profiles = df_movies[df_movies[\"movieId\"].isin(df_tags[\"movieId\"])]\n",
    "item_profiles\n",
    "df_lexicon\n",
    "# you can drop the userId and timestamp columns because we don't care who assigned the tag and when\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/l9b6fpv12v370f32ct4y00h00000gn/T/ipykernel_1786/2621643708.py:3: FutureWarning: ['userId', 'timestamp'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  df_features = df_tags.groupby('movieId').agg(lambda x: ' '.join(x)).reset_index()\n",
      "/Users/alexanderwermuth/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>feature_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pixar pixar fun</td>\n",
       "      <td>(0, 1016)\\t0.8992312620852461\\n  (0, 513)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>fantasy magic_board_game robin_williams game</td>\n",
       "      <td>(0, 1129)\\t0.48431677463057304\\n  (0, 812)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moldy old</td>\n",
       "      <td>(0, 967)\\t0.7071067811865475\\n  (0, 876)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>pregnancy remake</td>\n",
       "      <td>(0, 1106)\\t0.6808321878901952\\n  (0, 1044)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>remake</td>\n",
       "      <td>(0, 1106)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>183611</td>\n",
       "      <td>comedy funny rachel_mcadams</td>\n",
       "      <td>(0, 1084)\\t0.7153847877740599\\n  (0, 515)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>184471</td>\n",
       "      <td>adventure alicia_vikander video_game_adaptation</td>\n",
       "      <td>(0, 1418)\\t0.6173008972335793\\n  (0, 46)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>187593</td>\n",
       "      <td>josh_brolin ryan_reynolds sarcasm</td>\n",
       "      <td>(0, 1156)\\t0.5453455400986055\\n  (0, 1147)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>187595</td>\n",
       "      <td>emilia_clarke star_wars</td>\n",
       "      <td>(0, 1266)\\t0.6876494487057803\\n  (0, 433)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>193565</td>\n",
       "      <td>anime comedy gintama remaster</td>\n",
       "      <td>(0, 1107)\\t0.5715745894656075\\n  (0, 536)\\t0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                              tag  \\\n",
       "0           1                                  pixar pixar fun   \n",
       "1           2     fantasy magic_board_game robin_williams game   \n",
       "2           3                                        moldy old   \n",
       "3           5                                 pregnancy remake   \n",
       "4           7                                           remake   \n",
       "...       ...                                              ...   \n",
       "1567   183611                      comedy funny rachel_mcadams   \n",
       "1568   184471  adventure alicia_vikander video_game_adaptation   \n",
       "1569   187593                josh_brolin ryan_reynolds sarcasm   \n",
       "1570   187595                          emilia_clarke star_wars   \n",
       "1571   193565                    anime comedy gintama remaster   \n",
       "\n",
       "                                         feature_vector  \n",
       "0       (0, 1016)\\t0.8992312620852461\\n  (0, 513)\\t0...  \n",
       "1       (0, 1129)\\t0.48431677463057304\\n  (0, 812)\\t...  \n",
       "2       (0, 967)\\t0.7071067811865475\\n  (0, 876)\\t0....  \n",
       "3       (0, 1106)\\t0.6808321878901952\\n  (0, 1044)\\t...  \n",
       "4                                        (0, 1106)\\t1.0  \n",
       "...                                                 ...  \n",
       "1567    (0, 1084)\\t0.7153847877740599\\n  (0, 515)\\t0...  \n",
       "1568    (0, 1418)\\t0.6173008972335793\\n  (0, 46)\\t0....  \n",
       "1569    (0, 1156)\\t0.5453455400986055\\n  (0, 1147)\\t...  \n",
       "1570    (0, 1266)\\t0.6876494487057803\\n  (0, 433)\\t0...  \n",
       "1571    (0, 1107)\\t0.5715745894656075\\n  (0, 536)\\t0...  \n",
       "\n",
       "[1572 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the sparse feature vector based on the TF-IDF of words in documents\n",
    "#the TF-IDF vectors are saved as sparse representations into the dataframe\n",
    "df_features = df_tags.groupby('movieId').agg(lambda x: ' '.join(x)).reset_index()\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(' ')).fit(sorted(df_features['tag']))\n",
    "vectorizer.vocabulary_\n",
    "df_features['feature_vector'] = df_features['tag'].apply(lambda x : vectorizer.transform([x]))\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Index item profiles into LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 6 stored elements in Compressed Sparse Row format>,\n",
       "   4552),\n",
       "  0.993541890821228),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 6 stored elements in Compressed Sparse Row format>,\n",
       "   628),\n",
       "  1.9999999999999996),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 5 stored elements in Compressed Sparse Row format>,\n",
       "   4370),\n",
       "  1.9999999999999998),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 6 stored elements in Compressed Sparse Row format>,\n",
       "   4816),\n",
       "  1.9999999999999998),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 19 stored elements in Compressed Sparse Row format>,\n",
       "   4878),\n",
       "  1.9999999999999998),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   2431),\n",
       "  1.9999999999999998),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   21),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 5 stored elements in Compressed Sparse Row format>,\n",
       "   6852),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   6773),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   6639),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 4 stored elements in Compressed Sparse Row format>,\n",
       "   6534),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   6334),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   6090),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   4902),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 13 stored elements in Compressed Sparse Row format>,\n",
       "   5673),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   7438),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   4639),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   4380),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   4262),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   4246),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   5954),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   7614),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   8235),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   8360),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   134130),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 6 stored elements in Compressed Sparse Row format>,\n",
       "   119141),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   117887),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 4 stored elements in Compressed Sparse Row format>,\n",
       "   80489),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   71494),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 3 stored elements in Compressed Sparse Row format>,\n",
       "   68237),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   52885),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 7 stored elements in Compressed Sparse Row format>,\n",
       "   45730),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   4160),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   40278),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   31437),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   30822),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   30793),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   27838),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   25825),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   8970),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 6 stored elements in Compressed Sparse Row format>,\n",
       "   8950),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   8530),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   34542),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   4024),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   3910),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1353),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1269),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1266),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1206),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   1197),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1035),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   991),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   943),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   936),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   926),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   736),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   475),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 3 stored elements in Compressed Sparse Row format>,\n",
       "   431),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   412),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   349),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   272),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   224),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   222),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   167746),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1610),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   187595),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1994),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   3528),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   3489),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   3310),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   3259),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   2987),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   2791),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   2717),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   2716),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1779),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   2710),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   2550),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2 stored elements in Compressed Sparse Row format>,\n",
       "   2424),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   2312),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   2186),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   2108),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1996),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   1995),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 1 stored elements in Compressed Sparse Row format>,\n",
       "   2565),\n",
       "  2.0),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 6 stored elements in Compressed Sparse Row format>,\n",
       "   115617),\n",
       "  2.0000000000000004),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 7 stored elements in Compressed Sparse Row format>,\n",
       "   1240),\n",
       "  2.0000000000000004),\n",
       " ((<1x1475 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 17 stored elements in Compressed Sparse Row format>,\n",
       "   3676),\n",
       "  2.0000000000000004)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = sparse.vstack(df_features[\"feature_vector\"])\n",
    "#index all item vectors into LSH\n",
    "lsh = LSH(4, m.shape[1], num_hashtables=1, storage_config={\"dict\":None})\n",
    "#run an example query to the LSH\n",
    "lsh.index(m, df_features[\"movieId\"])\n",
    "query = np.zeros(m.shape[1])\n",
    "query[0] = 1\n",
    "print(csr_matrix(query))\n",
    "lsh.query(csr_matrix(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies reduced from 9724 to 9724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "1           4.0     NaN     4.0     NaN     NaN     4.0     NaN     NaN   \n",
       "2           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "606         2.5     NaN     NaN     NaN     NaN     NaN     2.5     NaN   \n",
       "607         4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         2.5     2.0     2.0     NaN     NaN     NaN     NaN     NaN   \n",
       "609         3.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         5.0     NaN     NaN     NaN     NaN     5.0     NaN     NaN   \n",
       "\n",
       "movieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
       "userId                   ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "606         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "607         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     4.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "609         NaN     4.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  193583  193585  193587  193609  \n",
       "userId                                   \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "2           NaN     NaN     NaN     NaN  \n",
       "3           NaN     NaN     NaN     NaN  \n",
       "4           NaN     NaN     NaN     NaN  \n",
       "5           NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...  \n",
       "606         NaN     NaN     NaN     NaN  \n",
       "607         NaN     NaN     NaN     NaN  \n",
       "608         NaN     NaN     NaN     NaN  \n",
       "609         NaN     NaN     NaN     NaN  \n",
       "610         NaN     NaN     NaN     NaN  \n",
       "\n",
       "[610 rows x 9724 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restricts the ratings to the set of most popular movies (optional, not needed for content-based)\n",
    "numratings_threshold = 0 #increase this number if you want to filter\n",
    "df_item_popularity = df_ratings[['movieId','rating']].groupby('movieId').count().reset_index()\n",
    "df_item_popularity.columns = ['movieId','count'] \n",
    "df_item_popularity = df_item_popularity.sort_values(by='count', ascending=False)\n",
    "df_item_popularity = df_item_popularity[df_item_popularity['count'] >= numratings_threshold]\n",
    "print(f'Number of movies reduced from {len(df_ratings.movieId.unique())} to {len(df_item_popularity.movieId.unique())}')\n",
    "df_ratings = pd.merge(df_ratings, df_item_popularity, on='movieId', how='inner')[['userId', 'movieId', 'rating']]\n",
    "df_ratings = df_ratings.sort_values(by='userId')\n",
    "\n",
    "# ----- SLIDE 12 FROM LECTURE 06 ------\n",
    "# rescale the ratings by the user's individual average \n",
    "# We do this by taking the average of the users rating and subtract the average with that movie rating. In other words we do a simple normalization\n",
    "mu = df_ratings.groupby(\"userId\").agg(avg=(\"rating\", \"mean\")).reset_index()\n",
    "df_ratings = df_ratings.merge(mu, on='userId')\n",
    "df_ratings['rating_scaled'] = df_ratings[\"rating\"] - df_ratings[\"avg\"]\n",
    "df_ratings.drop([\"avg\"], axis=1) \n",
    "\n",
    "df_ratings.head()\n",
    "preprocessing.minmax_scale(df_ratings)\n",
    "df_ratings.pivot_table(index='userId', columns='movieId', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rating_scaled'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating_scaled'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m df_profile \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(df_ratings, df_features[[\u001b[39m'\u001b[39m\u001b[39mmovieId\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mfeature_vector\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m      3\u001b[0m               on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmovieId\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m#scaling feature vector by rating (this will take a few minutes)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df_profile[\u001b[39m'\u001b[39m\u001b[39mfeature_vector_scaled\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_profile[\u001b[39m'\u001b[39;49m\u001b[39mrating_scaled\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m*\u001b[39m df_profile[\u001b[39m'\u001b[39m\u001b[39mfeature_vector\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m df_profile\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating_scaled'"
     ]
    }
   ],
   "source": [
    "# join ratings with movie feature vectors\n",
    "df_profile = pd.merge(df_ratings, df_features[['movieId','feature_vector']],\n",
    "              on='movieId')\n",
    "#scaling feature vector by rating (this will take a few minutes)\n",
    "df_profile['feature_vector_scaled'] = df_profile['rating_scaled'] * df_profile['feature_vector']\n",
    "df_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['feature_vector_scaled'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      2\u001b[0m \u001b[39m#stack all sparse vectors of user's movies\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_user_vectors \u001b[39m=\u001b[39m df_profile[[\u001b[39m'\u001b[39;49m\u001b[39muserId\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfeature_vector_scaled\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39muserId\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39magg(sparse\u001b[39m.\u001b[39mvstack)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m      4\u001b[0m \u001b[39m#compute the average of the vectors without considering the zero entries (this will take a while)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_user_vectors[\u001b[39m'\u001b[39m\u001b[39mfeature_vector_scaled\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_user_vectors[\u001b[39m'\u001b[39m\u001b[39mfeature_vector_scaled\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: csr_matrix(np\u001b[39m.\u001b[39mnan_to_num(x\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m/\u001b[39mx\u001b[39m.\u001b[39mgetnnz(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), \u001b[39m0\u001b[39m)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data-in-production/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['feature_vector_scaled'] not in index\""
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#stack all sparse vectors of user's movies\n",
    "df_user_vectors = df_profile[['userId', 'feature_vector_scaled']].groupby('userId').agg(sparse.vstack).reset_index()\n",
    "#compute the average of the vectors without considering the zero entries (this will take a while)\n",
    "df_user_vectors['feature_vector_scaled'] = df_user_vectors['feature_vector_scaled'].apply(lambda x: csr_matrix(np.nan_to_num(x.sum(axis=0)/x.getnnz(axis=0), 0)))\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "df_user_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Rank potential recommendation candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a target user to provide recommendations to\n",
    "idx = 42\n",
    "target_userId = df_user_vectors.iloc[idx].userId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get user rating history\n",
    "df_user_history = ...\n",
    "\n",
    "#select candidate recommendations to user\n",
    "df_recommendation = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_history.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_history.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Predict ratings of candidate items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index all user vectors into LSH\n",
    "df_usr = df_profile[df_profile['userId'] == target_userId]\n",
    "lsh_usr = LSH(...)\n",
    "lsh_usr.index(..., extra_data=[...]) # repeat for all users. Insert movieid and rating as extra data for future retrieval\n",
    "lsh_usr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute recommendation\n",
    "df_recommendation = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m SVD\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m Reader\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms.knns import KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/movielens/ml-latest-small'\n",
    "#directory = 'data/movielens/ml-latest' #change into this one for the full dataset (slow)\n",
    "df_ratings = pd.read_csv(f'{directory}/ratings.csv')\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a data reader\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# provide a dataset with userid, itemtid, and rating in order\n",
    "data = Dataset.load_from_df(df_ratings[['userId','movieId','rating']], reader)\n",
    "\n",
    "# surprise has also some built-in datasets that can be imported directly\n",
    "#data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a user-based K nearest neighbors implementation\n",
    "...\n",
    "# execute 5-fold cross-validation and measure RMSE and MAE\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "296.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
